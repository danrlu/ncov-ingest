#!/usr/bin/env python3
"""
Download BioSample records for the BioSample accessions provided in the
GenBank NDJSON.

Outputs newline-delimited JSON records.
"""
import argparse
import json
from sys import stdout
from typing import Set, List, Dict, Any
from pathlib import Path
from Bio import Entrez
from more_itertools import chunked
import xmltodict

# The expected biosample accession field name according to the renaming of
# fields done in `fetch-from-genbank`
BIOSAMPLE_FIELD_NAME = 'biosample_accession'
# The maximum number of records that can be retrieved from Entrez.EFetch
CHUNK_SIZE = 10000


def load_biosample_accessions(genbank_file: str) -> Set[str]:
    """
    Load the biosample accessions in the given NDJSON *genbank_file*
    Append the suffix "[accn]", which is used in Entrez.ESearch
    Return set of biosample accessions
    """
    biosample_accessions = set()
    with open(genbank_file) as genbank_fh:
        for line in genbank_fh:
            biosample_accn = json.loads(line)[BIOSAMPLE_FIELD_NAME]
            if biosample_accn:
                biosample_accn += '[accn]'
                biosample_accessions.add(biosample_accn)

    return biosample_accessions


def fetch_biosample_data(biosample_accessions: List[str]) -> List[Dict[str, Any]]:
    """
    Use the BioSample accessions in *genbank_data* to search and fetch
    BioSample records for extra metadata.
    """
    search_db = 'biosample'
    Entrez.email = 'hello@nextstrain.org'

    # Search using the Entrez History Server to temporarily store the UIDs
    # on the server, so we don't have to round-trip the UIDs.
    search_history = Entrez.read(Entrez.esearch(usehistory='y',
                                                db=search_db,
                                                term=' or '.join(biosample_accessions)))

    # Fetch BioSample records using the stored UIDs on the server
    # The stored UIDs are accessed via QueryKey & WebEnv returned by ESearch.
    efetch_result = Entrez.efetch(db=search_db,
                                  query_key = search_history['QueryKey'],
                                  WebEnv = search_history['WebEnv'])
    # Entrez.read() currently does not work with BioSample XMLs because they
    # do not have a properly formatted DTD. So we need to parse the XML ourselves.
    # Convert the returned XML to dict for easier data access
    biosample_data = xmltodict.parse(efetch_result)

    return biosample_data['BioSampleSet']['BioSample']


def parse_biosample(biosample_record: Dict[str, Any]) -> Dict[str, Any]:
    """
    Parse the nested *biosample_record* into a flat dictionary that
    contains the BioSample accession and all of the record's attributes.

    All standardized attributes for BioSample records can be found at
    https://www.ncbi.nlm.nih.gov/biosample/docs/attributes/
    """
    parsed_record = {}
    parsed_record['biosample_accession'] = biosample_record['@accession']

    for attribute in biosample_record['Attributes']['Attribute']:
        # @harmonzied_name is the short, canonical attribute name that only
        # exists for the standardized attributes. Fallback to the human
        # readable @attribute_name if the @harmonzied_name doesn't exist
        attribute_name = attribute.get('@harmonized_name') or attribute.get('@attribute_name')
        if not attribute_name:
            continue

        # #text is the value of the attribute
        parsed_record[attribute_name] = attribute['#text']

    return parsed_record


if __name__ == '__main__':
    base = Path(__file__).resolve().parent.parent

    parser = argparse.ArgumentParser(
        description=__doc__,
        formatter_class=argparse.RawTextHelpFormatter)
    parser.add_argument("genbank_data",
        default=base / "data/genbank.ndjson",
        nargs="?",
        help="Newline-delimited GenBank JSON data")

    args = parser.parse_args()

    biosample_accessions = load_biosample_accessions(args.genbank_data)

    # Fetch BioSample data in chunks since EFetch has a limit of records
    # it can retrieve in one request
    for subset in chunked(biosample_accessions, n=CHUNK_SIZE):
        for sample in fetch_biosample_data(subset):
            sample = parse_biosample(sample)
            json.dump(sample, stdout, allow_nan = False, indent = None, separators = ',:')
            print()
